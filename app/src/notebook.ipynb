{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(text, speaker_wav_path, language, output_file_path):\n",
    "    tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\", progress_bar=True).to(DEVICE)\n",
    "    # Generar el archivo de audio a partir del texto\n",
    "    tts.tts_to_file(text=text, speaker_wav=speaker_wav_path, language=language, file_path=output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supported_lang(iso_code):\n",
    "    languages = {\n",
    "        'en': 'English',\n",
    "        'fr': 'French',\n",
    "        'de': 'German',\n",
    "        'it': 'Italian',\n",
    "        'ar': 'Arabic'\n",
    "    }\n",
    "    return iso_code in languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whisper_transcribe_audio(model, audio_data_path):\n",
    "    audio = whisper.load_audio(audio_data_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "   # Representación útil para el procesamiento de audio que enfatiza las frecuencias importantes\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    # Detectar el idioma hablado\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(model.detect_language(mel))\n",
    "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "    detected_language = max(probs, key=probs.get)\n",
    "\n",
    "    # Ayudar al modelo con el idioma origen, aunque no es necesario\n",
    "    options = whisper.DecodingOptions(language=detected_language, task=\"transcribe\", without_timestamps=True)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    # Devolver la transcripción\n",
    "    return result.text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whisper_detect_lang_and_transcribe_audio(model, audio_data_path):\n",
    "    audio = whisper.load_audio(audio_data_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "   # Representación útil para el procesamiento de audio que enfatiza las frecuencias importantes\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    # Detectar el idioma hablado\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(model.detect_language(mel))\n",
    "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "    detected_language = max(probs, key=probs.get)\n",
    "\n",
    "    # Ayudar al modelo con el idioma origen, aunque no es necesario\n",
    "    options = whisper.DecodingOptions(language=detected_language, task=\"transcribe\", without_timestamps=True)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    # Devolver la transcripción\n",
    "    return detected_language, result.text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_from_esp_to_lang(lang, transcription):\n",
    "    if supported_lang(lang):\n",
    "        try:\n",
    "            translator = pipeline(\"translation\", model=f\"Helsinki-NLP/opus-mt-es-{lang}\")\n",
    "            result = translator(transcription) \n",
    "            return result[0]['translation_text']\n",
    "        except Exception as e:\n",
    "            print(\"Error durante la traducción :\", e)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_from_lang_to_esp(lang, transcription):\n",
    "    if supported_lang(lang):\n",
    "        try:\n",
    "            translator = pipeline(\"translation\", model=f\"Helsinki-NLP/opus-mt-{lang}-es\")\n",
    "            result = translator(transcription) \n",
    "            return result[0]['translation_text']\n",
    "        except Exception as e:\n",
    "            print(\"Error durante la traducción :\", e)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is multilingual \n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\", device=DEVICE)\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "def process_audio(audio_data_mic_path, audio_data_file_path, target_lang=\"en\"):\n",
    "\n",
    "    if audio_data_mic_path is None or os.path.getsize(audio_data_mic_path) == 0:\n",
    "        audio_data = audio_data_file_path\n",
    "    else:\n",
    "        audio_data = audio_data_mic_path\n",
    "\n",
    "    # Transcripción del Audio\n",
    "\n",
    "    transcription = whisper_transcribe_audio(model, audio_data)\n",
    "    print(transcription)\n",
    "\n",
    "    # Traducción del audio al idioma objetivo\n",
    "    translation = translation_from_esp_to_lang(target_lang, transcription)\n",
    "\n",
    "    output_file_path = \"output/output.wav\"\n",
    "\n",
    "    generate_audio(translation, audio_data, target_lang, output_file_path)\n",
    "\n",
    "    return transcription, translation, output_file_path\n",
    "\n",
    "# Crear la interfaz de Gradio\n",
    "iface = gr.Interface(\n",
    "    fn = process_audio,\n",
    "    inputs = \n",
    "        [\n",
    "        gr.Audio(sources=\"upload\", type=\"filepath\", label=\"Archivo de audio\"),\n",
    "        gr.Audio(sources=\"microphone\", type=\"filepath\", label=\"Graba tu audio\"),\n",
    "        gr.Dropdown(\n",
    "                    ['en','fr', 'de', 'it', 'ar'], \n",
    "                    label=\"Idioma a Traducir\", info=\"Info adicional\"\n",
    "        ),\n",
    "        ],\n",
    "    outputs=\n",
    "        [\n",
    "        gr.Textbox(label=\"Transcripción\"), \n",
    "        gr.Textbox(label=\"Traducción\"), \n",
    "        gr.Audio(type=\"filepath\", label=\"Audio generado\")\n",
    "        ],\n",
    "    title=\"Audio y Transcripcion\",\n",
    "    description=\"Graba tu voz y transcribela a texto.\",\n",
    "    allow_flagging = \"never\"\n",
    ")\n",
    "\n",
    "# Ejecutar la interfaz\n",
    "iface.launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(50272), {'fa': 5.316548140399391e-06, 'sd': 1.3984866598093504e-07, 'tk': 5.117600787585275e-10, 'sa': 2.1366770397435175e-06, 'ta': 2.1097046101203887e-06, 'hr': 4.445303503075593e-08, 'jw': 1.7620612197788432e-05, 'si': 1.578731030349445e-06, 'oc': 1.5647387954231817e-06, 'nl': 1.585925383551512e-05, 'ps': 1.3039128816672019e-06, 'kk': 1.6700958838100632e-07, 'mk': 3.944379756148919e-08, 'hi': 6.9065849856997374e-06, 'yo': 1.5734492535557365e-06, 'haw': 1.0623280104482546e-05, 'mt': 1.672275288910896e-06, 'ht': 7.91949958056648e-07, 'bn': 2.448391569487285e-07, 'ln': 6.307045197218031e-08, 'bg': 1.4368102085882128e-07, 'yi': 6.737678859281004e-07, 'en': 0.00028171049780212343, 'kn': 8.622353675491468e-08, 'cy': 1.1375354915799107e-05, 'gu': 1.1640166164283983e-08, 'th': 7.942106776681612e-07, 'ca': 1.2773765547535731e-06, 'sn': 3.159991138090845e-06, 'da': 1.0267229981764103e-06, 'nn': 1.8076047126669437e-05, 'br': 9.232729098584969e-06, 'ur': 5.070365295978263e-05, 'el': 8.963072468759492e-05, 'ba': 3.7497485672055575e-10, 'mn': 5.961316560387786e-07, 'am': 2.243316714611865e-07, 'hu': 9.571795089868829e-06, 'zh': 1.0179060154769104e-05, 'ha': 2.7690352233378235e-09, 'vi': 4.4879754568682984e-05, 'km': 4.29095734943985e-06, 'hy': 2.9948921564937336e-07, 'tl': 3.674980689538643e-05, 'sq': 1.0150298379585365e-07, 'ml': 1.302173131989548e-06, 'tt': 5.500302879823948e-09, 'et': 2.0022771707317588e-07, 'he': 5.9077265177620575e-05, 'de': 6.813871004851535e-05, 'ro': 1.4443099644267932e-05, 'fo': 2.979327007324173e-07, 'id': 1.9379476725589484e-05, 'fr': 0.0002713216526899487, 'it': 7.702990114921704e-05, 'lo': 3.097543128660618e-07, 'ms': 0.00012693846656475216, 'uz': 8.579232879668552e-10, 'fi': 9.242088481187238e-07, 'ja': 1.0487756298971362e-05, 'ne': 7.188241823996577e-08, 'bo': 2.634505165133305e-07, 'tr': 0.00013436918379738927, 'sv': 6.6656607486947905e-06, 'cs': 7.113516744539083e-07, 'no': 2.357820676479605e-06, 'as': 1.1143389322398889e-08, 'te': 2.973913524328964e-07, 'pt': 8.597876330895815e-06, 'su': 9.884039142704637e-10, 'uk': 5.513879273166822e-07, 'az': 1.7651937014306895e-06, 'gl': 9.193888104164216e-07, 'af': 5.668659355251293e-07, 'la': 1.877268368843943e-05, 'tg': 2.0881543605355546e-08, 'pl': 1.7000384104903787e-05, 'eu': 7.543374636043154e-07, 'be': 3.7679103570553707e-07, 'sk': 1.1938203314798557e-08, 'my': 3.017351275502733e-07, 'mi': 1.1256082643740228e-06, 'lt': 1.119204497967985e-07, 'ar': 0.9983423948287964, 'ko': 9.257243800675496e-05, 'sw': 8.858759201757493e-07, 'mr': 3.935444681246736e-08, 'ka': 1.3869758674900368e-08, 'bs': 3.269806114758467e-08, 'pa': 2.3457060649434425e-07, 'mg': 2.958802369779079e-10, 'lb': 2.394622944379421e-09, 'so': 1.1816832738986704e-06, 'sl': 7.419785106321797e-07, 'es': 5.175184196559712e-05, 'sr': 1.0183667242813499e-08, 'lv': 5.1074842133402854e-08, 'ru': 1.9473256543278694e-05, 'is': 4.537159554729442e-07})\n",
      "Detected language: ar\n",
      "مرحباً أنا المتحدث الافتراضي من إمضاء الجودة داني ألقي التحيطة على جمهورك وعرفهم على منتجاتك عبر وسيلة من أكثر الوسائل التسويقية تشويقا ومتعى\n",
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #  # # #   # # # # # # # # # # # # #  # #   # # #              # # # #      # # # # #    #            #                         #  # # # # # # # # # # # # #       # # # # # # #    # # #               #         # # # # # # # # # # # #    # # # #   #  # # # # #               #                                  #']\n",
      "[!] Warning: The text length exceeds the character limit of 250 for language 'en', this might cause truncated audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/gradio/queueing.py\", line 528, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/gradio/blocks.py\", line 1908, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/gradio/blocks.py\", line 1485, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/gradio/utils.py\", line 808, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_882034/3474078657.py\", line 18, in process_audio\n",
      "    generate_audio(translation, audio_data, target_lang, output_file_path)\n",
      "  File \"/tmp/ipykernel_882034/1415145976.py\", line 4, in generate_audio\n",
      "    tts.tts_to_file(text=text, speaker_wav=speaker_wav_path, language=language, file_path=output_file_path)\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/TTS/api.py\", line 334, in tts_to_file\n",
      "    wav = self.tts(\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/TTS/api.py\", line 276, in tts\n",
      "    wav = self.synthesizer.tts(\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/TTS/utils/synthesizer.py\", line 386, in tts\n",
      "    outputs = self.tts_model.synthesize(\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/TTS/tts/models/xtts.py\", line 419, in synthesize\n",
      "    return self.full_inference(text, speaker_wav, language, **settings)\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/TTS/tts/models/xtts.py\", line 488, in full_inference\n",
      "    return self.inference(\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/bmontes/miniconda3/envs/whisper-coqui/lib/python3.9/site-packages/TTS/tts/models/xtts.py\", line 536, in inference\n",
      "    assert (\n",
      "AssertionError:  ❗ XTTS can only generate text with a maximum of 400 tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_audio(audio_data_mic_path, audio_data_file_path):\n",
    "\n",
    "    if audio_data_mic_path is None or os.path.getsize(audio_data_mic_path) == 0:\n",
    "        audio_data = audio_data_file_path\n",
    "    else:\n",
    "        audio_data = audio_data_mic_path\n",
    "\n",
    "    # Transcripción del Audio\n",
    "\n",
    "    detected_lang, transcription = whisper_detect_lang_and_transcribe_audio(model, audio_data)\n",
    "    print(detected_lang)\n",
    "    print(transcription)\n",
    "\n",
    "    # Traducción del audio al idioma objetivo\n",
    "    translation = translation_from_lang_to_esp(detected_lang, transcription)\n",
    "\n",
    "    output_file_path = \"output/output.wav\"\n",
    "\n",
    "    generate_audio(translation, audio_data, \"es\", output_file_path)\n",
    "\n",
    "    return transcription, translation, output_file_path\n",
    "\n",
    "# Crear la interfaz de Gradio\n",
    "iface = gr.Interface(\n",
    "    fn = process_audio,\n",
    "    inputs = \n",
    "        [\n",
    "        gr.Audio(sources=\"upload\", type=\"filepath\", label=\"Audio File\"),\n",
    "        gr.Audio(sources=\"microphone\", type=\"filepath\", label=\"Record your audio\"),\n",
    "        ],\n",
    "    outputs=\n",
    "        [\n",
    "        gr.Textbox(label=\"Transcripción\"), \n",
    "        gr.Textbox(label=\"Translation\"), \n",
    "        gr.Audio(type=\"filepath\", label=\"Audio generated\")\n",
    "        ],\n",
    "    title=\"Audio and Transcription\",\n",
    "    description=\"Record your voice and transcribe it to text.\",\n",
    "    allow_flagging = \"never\"\n",
    ")\n",
    "\n",
    "# Ejecutar la interfaz\n",
    "iface.launch(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper-coqui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
